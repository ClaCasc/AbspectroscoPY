{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### User input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decimal = '.'                                                   # decimal of the input file\n",
    "sep = ';'                                                       # separator of the input file\n",
    "input_dir = 'C:/Users/cace0002/AbspectroscoPY/data_scan_fp/'    # input directory\n",
    "output = 'C:/Users/cace0002/AbspectroscoPY/results/'            # output directory\n",
    "filepattern = '*.csv'                                           # format of the files to import\n",
    "header_rownr = 1                                                # header row number\n",
    "possibledateheadernames = ['Date', 'Time', 'Date/Time', 'Timestamp','Measurement interval=120[sec] (Export-Aggregation disabled)'] # input possible headers of the date column \n",
    "dateparsingformat = '%Y-%m-%d %H:%M:%S'                         # format of the date \n",
    "ncol_expected = 223                                             # number of columns expected per file\n",
    "drop_c1 = 'Status (Source:0)'                                   # name of columns to drop; input extra labels, if more than one column needs to be dropped (['variable_name1','variable_name2'])\n",
    "sample_name = 'sw'                                              # name of the sample"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Start environment "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import abspectroscopy_functions as abspy # Functions from the AbspectroscoPY toolbox\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define and run functions prior to abs_read"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functions besides the ones reported in \"abspectroscopy_functions.py\":\n",
    "def remove_parentheses(input_dir, rownr, removeparentheses):\n",
    "    '''\n",
    "    function to remove parentheses\n",
    "    '''\n",
    "    import re\n",
    "    indata = open(input_dir, 'r')\n",
    "    i = 0\n",
    "    newline=None\n",
    "    for line in indata:\n",
    "        i = i + 1\n",
    "        if (rownr == i):\n",
    "            newline = line.replace(';', '\\t')  \n",
    "            if removeparentheses:\n",
    "                newline = re.sub(r'\\([^)]*\\)', '', newline) \n",
    "            break            \n",
    "    indata.close()\n",
    "    return newline\n",
    "\n",
    "def check_headers_name_and_order(listoffiles, rownr=2):\n",
    "    '''\n",
    "        function to check if the headers of the files are identical (first check) and if they have the same position (second check)\n",
    "\n",
    "        :argument listoffiles: A list of files that will be compared against eachother\n",
    "        :argument rownr: The rownr containing the headers\n",
    "        :return: void\n",
    "    '''\n",
    "    import os\n",
    "    aset = set()\n",
    "    aset_includingcalibtext = set()\n",
    "\n",
    "    for afile in listoffiles:\n",
    "        indatafile=afile\n",
    "        arow = remove_parentheses(indatafile,  rownr, removeparentheses=True)\n",
    "        arowwithparentheses = remove_parentheses(indatafile, rownr, removeparentheses=False)\n",
    "        aset.add(arow)\n",
    "        aset_includingcalibtext.add(arowwithparentheses)\n",
    "\n",
    "    for oneset in aset_includingcalibtext:\n",
    "        print(\"****** FIRST TYPE OF CHECK *******\")\n",
    "        print(oneset)\n",
    "    if len(aset_includingcalibtext)>1:\n",
    "        print(\" !!! Warning: one, but probably, many missmatching strings in headers, !!!\")\n",
    "        print(\" !!! Warning: this may result in loss of data !!!\")\n",
    "        print(\" -- If second type of check pass, then it is ok to read files by order (not by header) --\")\n",
    "    else:\n",
    "        print(\"-- First check passed, i.e all headers are identical --\")\n",
    "        \n",
    "    for ast in aset:\n",
    "        print(\"\\n\\n****** SECOND TYPE OF CHECK *******\")\n",
    "        print(ast)\n",
    "    if len(aset)>1:\n",
    "        print(\" !!! Warning: one, but probably, many missmatching order of headers !!!\")\n",
    "    else:\n",
    "        print(\"-- Second check passed i.e. all headers have the same position --\")\n",
    "        \n",
    "    print(\"\\nFinished check\")\n",
    "    \n",
    "def dateparse(x):\n",
    "    '''\n",
    "       function to convert a string to datetime using strptime () function\n",
    "    '''\n",
    "    parsed = pd.datetime.strptime(x, dateparsingformat)\n",
    "    return parsed\n",
    "\n",
    "def check_number_columns(listoffileswithpath, listoffilesnopath, sep, decimal, dateheadername, dateparse, ncol_expected):  \n",
    "    '''\n",
    "       function to check if all the files have a specific number of columns\n",
    "\n",
    "        :argument listoffileswithpath: A list of files that will be compared against eachother.\n",
    "        :argument listoffilesnopath: A list of files that will be compared against eachother.\n",
    "        :argument sep: Field separator.\n",
    "        :argument decimal: Notation for decimal.\n",
    "        :argument dateheadername: Header name for field containing dates.\n",
    "        :argument dateparse: Calling function datepares to treat date in the expected format.\n",
    "        :argument ncol_expected: The expected number of columns for indata files.\n",
    "        :return: void.\n",
    "    '''\n",
    "  \n",
    "    dfdiagnostic = pd.DataFrame(columns=['nr_col','filename'])\n",
    "    i=0\n",
    "    totfiles = len(listoffileswithpath)\n",
    "    for file, fileshort in zip(listoffileswithpath, listoffilesnopath):\n",
    "        i=i+1\n",
    "        if True:\n",
    "            infile_csv = file\n",
    "            print(\"Processing : \"+str(i)+\"/\"+str(totfiles)+\" \"+ file) \n",
    "            endf = pd.read_csv(filepath_or_buffer=infile_csv, sep=sep, header=header_rownr, index_col=1, \n",
    "                                decimal=decimal, low_memory=False , parse_dates=[dateheadername], \n",
    "                                date_parser=dateparse)\n",
    "            endf.reset_index(level=0, inplace=True)\n",
    "            nrcol = len(endf.columns)\n",
    "            dfdia = pd.DataFrame([[nrcol, fileshort]], columns=[\"nr_col\",\"filename\"])\n",
    "            dfdiagnostic = dfdiagnostic.append(dfdia, ignore_index = True, sort=False)    \n",
    "    print('Different number of columns from the expected one:', dfdiagnostic.loc[dfdiagnostic[\"nr_col\"] != ncol_expected])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "listoffileswithpath,listoffilesnopath = abspy.get_files_list(input_dir, filepattern) # get the list of files with a specific pattern\n",
    "listoffileswithpath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dateheadername = abspy.guess_date_column(listoffileswithpath, possibledateheadernames, header_rownr+1) # determine the name of the date column using a list of possible date column names \n",
    "dateheadername"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check_headers_name_and_order(listoffileswithpath, header_rownr+1) # check if the headers of the files are identical (first check) and if they have the same position (second check)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check_number_columns(listoffileswithpath, listoffilesnopath, sep, decimal, dateheadername, dateparse, ncol_expected) #check if all the files have the right number of columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### abs_read"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def abs_read(listoffileswithpath, \n",
    "             listoffilesnopath,\n",
    "             header_rownr,                          \n",
    "             dateheadername,\n",
    "             drop_col):  \n",
    "    '''\n",
    "    function to import a list of attenuation data files as function of time\n",
    "    :argument listoffileswithpath: list of files including path (output of the function \"get_files_list\")\n",
    "    :argument listoffilesnopath: list of files without path (output of the function \"get_files_list\")\n",
    "    :argument header_rownr: header row number\n",
    "    :argument dateheadername: name of the date column (output of the function \"guess_date_column\")\n",
    "    :argument drop_col: drop useless columns   \n",
    "    :return: dataframe with the attenuation data as function of time\n",
    "    '''        \n",
    "    df= pd.DataFrame() \n",
    "    i=0\n",
    "    totfiles = len(listoffileswithpath)\n",
    "    for file, fileshort in zip(listoffileswithpath, listoffilesnopath):\n",
    "        i=i+1\n",
    "        if True:\n",
    "            infile_csv = file\n",
    "            print(\"Processing : \"+str(i)+\"/\"+str(totfiles)+\" \"+ file) \n",
    "            endf = pd.read_csv(filepath_or_buffer=infile_csv, sep=sep, header=header_rownr, index_col=1, \n",
    "                                decimal=decimal, low_memory=False , parse_dates=[dateheadername], \n",
    "                                date_parser=dateparse)\n",
    "            endf.reset_index(level=0, inplace=True)\n",
    "            df = df.append(endf, ignore_index = True, sort=False)\n",
    "    df = df.set_index(dateheadername)                # set the date as index\n",
    "    df = df.drop(drop_col, axis=1)                   # drop useless columns\n",
    "    df_out = df.copy()\n",
    "    df_out.index = df_out.index.rename('Timestamp')  # rename the index column as \"Timestamp\"\n",
    "    return(df_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = abs_read(listoffileswithpath, listoffilesnopath, header_rownr, dateheadername, drop_c1)    # import the list of files\n",
    "df.to_csv(output + 'df_' + str(sample_name) + '.csv', sep = sep, decimal = decimal, index=True) # export the dataset\n",
    "df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
