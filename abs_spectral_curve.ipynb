{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### User input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decimal = '.'                                                                   # decimal of the input file\n",
    "sep = ';'                                                                       # separator of the input file\n",
    "\n",
    "from config import *                                                            # Personal settings of local user to set input and output directories\n",
    "input_dir = input_directory + 'results/df_mediancor_sw_30.0.csv'                # input directory\n",
    "output = output_directory + 'results/'                                          # output directory\n",
    "\n",
    "headername = 'Timestamp'                                                        # header of the date  \n",
    "header = 0                                                                      # header row number\n",
    "dateparsingformat = '%Y-%m-%d %H:%M:%S'                                         # format of the date \n",
    "sample_name = 'sw'                                                              # name of the sample\n",
    "\n",
    "S_f = 1                                                                         # sampling frequency\n",
    "start_date = '2018-11-13 05:02:00'                                              # define the range of dates for which we \n",
    "end_date = '2018-12-03 20:44:00'                                                # want to generate the spectral curve\n",
    "r2threshold = 0.98                                                              # correlation coefficient (R2) threshold to filter the negative spectral slope results\n",
    "year = 'november_december_2018'                                                 # title when saving the csv files        \n",
    "\n",
    "#To plot the time series of negative spectral slope, the user can modify:\n",
    "col_sel_sc = '254.5'                                                            # column to plot\n",
    "timestart = '2018-11-13 04:32:00'                                               # starting time and ending time\n",
    "timeend =   '2018-12-03 20:44:00'                                \n",
    "ylabel = 'Negative spectral slope [nm $^{-1}$]'                                 # label y-axis\n",
    "title1 = 'spectral_curve_'                                                      # title of the exported figure 1\n",
    "fig_format = '.tiff'                                                            # format of the exported figure\n",
    "dpi = 300                                                                       # resolution of the exported figure\n",
    "\n",
    "\n",
    "# To plot the time series of changes (%) ratio of negative spectral slope data, the user can modify:\n",
    "date_ref_start = '2018-11-13 05:02:00'                                          # define reference period for computing the changes\n",
    "date_ref_end = '2018-11-14 05:02:00'\n",
    "ylabel2 = 'Negative spectral slope change [%]'                                  # label y-axis\n",
    "title2 = 'spectral_curve_changes'                                               # title of the exported figure 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Start environment and import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import abspectroscopy_functions as abspy # Functions from the AbspectroscoPY toolbox\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "from matplotlib.ticker import (MultipleLocator, FormatStrFormatter, AutoMinorLocator)\n",
    "from datetime import datetime\n",
    "from scipy import interpolate\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "df = pd.read_csv(input_dir, sep = sep, header = header, index_col = 0) \n",
    "df.index = pd.to_datetime(df.index)      # make sure time column (here index) is using time format\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### abs_spectral_curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def abs_spectral_curve(df_in, \n",
    "                       starting_date,\n",
    "                       ending_date,\n",
    "                       dateparsingformat,\n",
    "                       sampling_frequency,\n",
    "                       r2): \n",
    "    '''\n",
    "    function to generate the spectral curve (get a dataframe with negative spectral slope values)\n",
    "    :argument df_in: dataframe in input\n",
    "    :argument starting_date: starting date\n",
    "    :argument ending_date: ending date\n",
    "    :argument dateparsingformat: format of the dates\n",
    "    :argument sampling_frequency: sampling frequency\n",
    "    :argument r2: R2 threshold\n",
    "    :return: a spectral curve dataframe including columns containing only NaN (df_out1) and a spectral curve dataframe without columns containing only NaN (df_out2)\n",
    "    '''\n",
    "    timestamp_selected = pd.date_range(start = starting_date, end = ending_date, periods = 2).tolist() # get the index of the rows corresponding to the defined timestamps to slice the dataframe\n",
    "    idx_vector = []\n",
    "    df_sc = df_in.copy()\n",
    "    df_sc = df_sc.reset_index()\n",
    "    for timestamp in timestamp_selected:\n",
    "        index_date_time = np.where(df_sc['Timestamp']==timestamp.strftime(dateparsingformat))[0] \n",
    "        idx = index_date_time[:][0]\n",
    "        idx_vector.append(idx)\n",
    "    ncol_in = idx_vector[0]                                         # specify that the first and second element of idx_vector are the columns where starting and ending slicing, respectively                                 \n",
    "    ncol_end = idx_vector[1] \n",
    "    df_sc = df_sc.T                                                 # transpose the data frame  \n",
    "    df_sc = df_sc.reset_index()                                     # restore the original index as row\n",
    "    headers = df_sc.iloc[0]                                         # rename the dates as headers                                     \n",
    "    df_sc = pd.DataFrame(df_sc.values[1:], columns=headers)         # convert the first row to header\n",
    "    df_sc = df_sc.rename(columns={\"Timestamp\": \"wl\"})               # rename the first column as \"wl\" = wavelength vector\n",
    "    df_sc['wl'] = df_sc['wl'].replace({'nm':''},regex=True)         # remove \"nm\" from the wavelength vector\n",
    "    wl = df_sc['wl'].apply(pd.to_numeric)                           # convert the wavelength vector to numeric  \n",
    "    if df_sc.columns.get_loc('wl') == ncol_in:                      # slice the dataframe, keeping the column \"wl\"\n",
    "        df_sc = df_sc.iloc[:, ncol_in:ncol_end]\n",
    "    else:\n",
    "        df_sc = df_sc.iloc[:, np.r_[0, ncol_in:ncol_end]]                      \n",
    "    headers = df_sc.columns        \n",
    "    iteration = len(df_sc.columns)                                  # number of loop iterations\n",
    "    print('number of iterations',iteration)\n",
    "    empty_matrix = np.zeros((iteration, 3))                         # create an empty matrix to fill in with the parameters s275_295, s350_400, SR for each datetime\n",
    "\n",
    "    interval = 21                                                   # the interval used to calculate each slope\n",
    "    xx = np.arange(min(wl),max(wl),1).astype(int)\n",
    "    wl_int=[]                                                       # compute number of average wavelength per interval\n",
    "    for i in range(min(xx),max(xx)-interval): \n",
    "        index = (xx >= i) & (xx <= i + interval)\n",
    "        wl_int.append(i + (interval / 2))\n",
    "    nwl   = len(wl_int)\n",
    "    ncol = len(df_sc.columns)\n",
    "    ndates = ncol_end-ncol_in\n",
    "    lin_reg = np.zeros((ndates,nwl))\n",
    "    lin_reg_r2 = np.zeros((ndates,nwl))\n",
    "    i=0\n",
    "    for i in range(0,ndates, sampling_frequency):  \n",
    "        print(i)\n",
    "        absorbance = df_sc.iloc[:,i]                                # the absorbance vector\n",
    "        #Resample data by 1 nm increment:\n",
    "        xx = np.arange(min(wl),max(wl),1).astype(int)\n",
    "        sf = interpolate.interp1d(wl, absorbance,kind='cubic')      # spline interpolation of third order\n",
    "        yy = sf(xx)\n",
    "        if min(yy)<0:    \n",
    "            yy = yy-min(yy)\n",
    "        xx_resh = xx.reshape((-1, 1))\n",
    "        yy_log_resh = np.log(yy).reshape((-1, 1))\n",
    "        yy_log_resh[yy_log_resh == float('-inf')]= np.NaN           # to replace -inf with NaN; in R \"NA\" says no result was available or the result is missing and it can be used in a matrix to fill in a value of a vector\n",
    "        np.isnan(yy_log_resh)                                       # to see if there are NaN values\n",
    "        yy=yy_log_resh[np.logical_not(np.isnan(yy_log_resh))].reshape((-1, 1)) # to remove (x, y) pairs where y is nan\n",
    "        xx=xx_resh[np.logical_not(np.isnan(yy_log_resh))]\n",
    "        for k, current_wl in enumerate(wl_int):             \n",
    "                index = (xx >= current_wl - interval/2) & (xx <= current_wl + interval/2)  \n",
    "                fit=LinearRegression().fit(xx[index].reshape((-1, 1)), yy[index]) \n",
    "                lin_reg[i,k]=-fit.coef_[0]\n",
    "                lin_reg_r2[i,k] = fit.score(xx[index].reshape((-1, 1)),yy[index])\n",
    "    colnames = [ str(col) for col in wl_int ]\n",
    "    sc_data = pd.DataFrame(lin_reg, index=headers[int(ncol_in/(ncol_in-1)):int(ncol_end-1/ncol_end)+(ndates-1)], columns=colnames) \n",
    "    sc_data_no_zero = sc_data.loc[(sc_data!=0).any(axis=1)]\n",
    "    sc_r2   = pd.DataFrame(lin_reg_r2, index=headers[int(ncol_in/(ncol_in-1)):int(ncol_end-1/ncol_end)+(ndates-1)], columns=colnames)  \n",
    "    sc_r2_no_zero = sc_r2.loc[(sc_r2!=0).any(axis=1)] \n",
    "    sc_data_r2 = sc_data_no_zero[sc_r2_no_zero>=r2threshold]         # to filter the data and keep only regression with r2 >= r2threshold\n",
    "    sc_data_r2 = sc_data_r2.dropna(axis=1, how='all')                # to drop the columns with only missing values\n",
    "    sc_data_r2_no_NaN = sc_data_r2.dropna(axis=1, how='any')         # to drop the columns with only missing values\n",
    "    sc_data_r2 = sc_data_r2.iloc[1:]\n",
    "    sc_data_r2.index = pd.to_datetime(sc_data_r2.index)              # make sure time column (here index) is using time format    \n",
    "    sc_data_r2.index = sc_data_r2.index.rename('Timestamp')          # rename the index column\n",
    "    sc_data_r2_no_NaN = sc_data_r2_no_NaN.iloc[1:]\n",
    "    sc_data_r2_no_NaN.index = pd.to_datetime(sc_data_r2_no_NaN.index)# make sure time column (here index) is using time format   \n",
    "    sc_data_r2_no_NaN.index = sc_data_r2_no_NaN.index.rename('Timestamp') \n",
    "    \n",
    "    df_out1 = sc_data_r2\n",
    "    df_out2 = sc_data_r2_no_NaN \n",
    "    return(df_out1, df_out2)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc_data_r2, sc_data_r2_no_NaN = abs_spectral_curve(df, start_date, end_date, dateparsingformat, S_f, r2threshold)\n",
    "#sc_data_r2.to_csv(output + 'df_sc_' + str(sample_name) + '_' + str(S_f) + '_' + str(year) +'.csv', index = True, sep = ';')\n",
    "#sc_data_r2_no_NaN.to_csv(output + 'df_sc_no_NaN_' + str(sample_name) + '_' + str(S_f) + '_' + str(year) +'.csv', index = True, sep = ';') # to drop the columns with any missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline # necessary if the notebook is not configured to use the inline backend by default\n",
    "#%matplotlib notebook\n",
    "plt.ion()\n",
    "abspy.makeaplot(sc_data_r2_no_NaN, output, col_sel_sc, timestart, timeend, sample_name, title1, ylabel = 'Negative spectral slope [nm $^{-1}$]')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute and visualise variation in negative spectral slope in terms of percentage changes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def abs_spectral_curve_perchanges(df_in,\n",
    "                                  date_ref_start,\n",
    "                                  date_ref_end,\n",
    "                                  dateparsingformat):\n",
    "    '''\n",
    "    function to compute the percentage changes of the negative spectral slope values in relation to a reference period\n",
    "    :argument df_in: dataframe in input\n",
    "    :argument date_ref_start: starting date of the reference period\n",
    "    :argument date_ref_end: ending date of the reference period\n",
    "    :argument dateparsingformat: format of the dates\n",
    "    return: a dataframe with percentage changes of the negative spectral slope values in relation to a reference period\n",
    "    '''\n",
    "    # Define a reference period:\n",
    "    date_ref_start1 = str(df_in.iloc[df_in.index.get_loc(date_ref_start, method='nearest')].name) # find the closest date to the date_ref_start and the second closest date to the date_ref_end available in the dataframe\n",
    "    date_ref_end1 = str(df_in.iloc[df_in.index.get_loc(date_ref_end, method='nearest')+1].name)\n",
    "    timestamp_selected = pd.date_range(start = date_ref_start1, end = date_ref_end1, periods = 2).tolist()\n",
    "    idx_vector = []\n",
    "    for timestamp in timestamp_selected:\n",
    "            index_date_time=np.where(df_in.index == timestamp.strftime(dateparsingformat))[0] # to check for specific date-time\n",
    "            idx=index_date_time[:][0]\n",
    "            idx_vector.append(idx)\n",
    "    #print('idx_vector:',idx_vector)\n",
    "\n",
    "    df_ref = df_in.copy()\n",
    "    df_ref = df_ref[idx_vector[0]:idx_vector[1]]\n",
    "\n",
    "    # Normalize the data by the average of the reference period and multiply by 100 to get %change:\n",
    "    df_ref_av = df_ref.mean()                          # compute the average of the vector\n",
    "    df_sub_ref_av = df_in.copy()\n",
    "    df_sub_ref_av = df_sub_ref_av - df_ref_av          # subtract this average to the vector\n",
    "    df_change_per = (df_sub_ref_av/abs(df_ref_av))*100 # compute the percent change\n",
    "\n",
    "    # Exclude from the dataset the reference period:\n",
    "    df_change_per = df_change_per.drop(df_change_per.index[idx_vector[0]:idx_vector[1]])\n",
    "    df_out = df_change_per\n",
    "    return(df_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sc_change_per = abs_spectral_curve_perchanges(sc_data_r2_no_NaN, date_ref_start, date_ref_end, dateparsingformat)\n",
    "df_sc_change_per.to_csv(output + 'df_sc_change_' + str(sample_name) + '_' + str(S_f) + '_' + str(year) +'.csv', index = True) # export the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%matplotlib inline \n",
    "%matplotlib notebook\n",
    "plt.ion()\n",
    "abspy.makeaplot(df_sc_change_per, output, col_sel_sc, timestart, timeend, sample_name, title2, ylabel = 'Negative spectral slope change [%]')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
